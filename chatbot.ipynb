{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file \n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']\n",
    "# os.environ['LANGSMITH_API_KEY']\n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "\n",
    "# from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings #para crear los embeddings https://python.langchain.com/docs/integrations/text_embedding\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter #para dividir los datos\n",
    "from langchain.vectorstores import Chroma #para almacenar los vectores de embeddings\n",
    "from pinecone import Pinecone #vectorstore\n",
    "from langchain.document_loaders import TextLoader #para cargar texto\n",
    "from langchain.chains import RetrievalQA,  ConversationalRetrievalChain #para recuperar los documentos\n",
    "from langchain.memory import ConversationBufferMemory #para crear un buffer de memoria\n",
    "from langchain.chat_models import ChatOpenAI \n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "import os\n",
    "import pandas as pd\n",
    "import objects\n",
    "import importlib #https://stackoverflow.com/questions/1254370/reimport-a-module-while-interactive\n",
    "import panel as pn\n",
    "import param\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'objects' from 'c:\\\\Users\\\\joaqu\\\\OneDrive\\\\Escritorio\\\\AI Projects\\\\Query_your_files\\\\objects.py'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(objects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fecha:2024-01-24\n",
      "Usando modelo gpt-3.5-turbo-0301\n",
      "Launching server at http://localhost:49900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<panel.io.server.Server at 0x1b4c55d56d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:bokeh.server.protocol_handler:error handling message\n",
      " message: Message 'PATCH-DOC' content: {'events': [{'kind': 'MessageSent', 'msg_type': 'bokeh_event', 'msg_data': {'type': 'event', 'name': 'button_click', 'values': {'type': 'map', 'entries': [['model', {'id': 'p2158'}]]}}}]} \n",
      " error: AttributeError(\"'NoneType' object has no attribute 'value'\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\joaqu\\OneDrive\\Escritorio\\Projects\\Building_Systems_ChatGPT\\llm_env\\lib\\site-packages\\bokeh\\server\\protocol_handler.py\", line 97, in handle\n",
      "    work = await handler(message, connection)\n",
      "  File \"c:\\Users\\joaqu\\OneDrive\\Escritorio\\Projects\\Building_Systems_ChatGPT\\llm_env\\lib\\site-packages\\bokeh\\server\\session.py\", line 94, in _needs_document_lock_wrapper\n",
      "    result = func(self, *args, **kwargs)\n",
      "  File \"c:\\Users\\joaqu\\OneDrive\\Escritorio\\Projects\\Building_Systems_ChatGPT\\llm_env\\lib\\site-packages\\bokeh\\server\\session.py\", line 288, in _handle_patch\n",
      "    message.apply_to_document(self.document, self)\n",
      "  File \"c:\\Users\\joaqu\\OneDrive\\Escritorio\\Projects\\Building_Systems_ChatGPT\\llm_env\\lib\\site-packages\\bokeh\\protocol\\messages\\patch_doc.py\", line 104, in apply_to_document\n",
      "    invoke_with_curdoc(doc, lambda: doc.apply_json_patch(self.payload, setter=setter))\n",
      "  File \"c:\\Users\\joaqu\\OneDrive\\Escritorio\\Projects\\Building_Systems_ChatGPT\\llm_env\\lib\\site-packages\\bokeh\\document\\callbacks.py\", line 443, in invoke_with_curdoc\n",
      "    return f()\n",
      "  File \"c:\\Users\\joaqu\\OneDrive\\Escritorio\\Projects\\Building_Systems_ChatGPT\\llm_env\\lib\\site-packages\\bokeh\\protocol\\messages\\patch_doc.py\", line 104, in <lambda>\n",
      "    invoke_with_curdoc(doc, lambda: doc.apply_json_patch(self.payload, setter=setter))\n",
      "  File \"c:\\Users\\joaqu\\OneDrive\\Escritorio\\Projects\\Building_Systems_ChatGPT\\llm_env\\lib\\site-packages\\bokeh\\document\\document.py\", line 376, in apply_json_patch\n",
      "    DocumentPatchedEvent.handle_event(self, event, setter)\n",
      "  File \"c:\\Users\\joaqu\\OneDrive\\Escritorio\\Projects\\Building_Systems_ChatGPT\\llm_env\\lib\\site-packages\\bokeh\\document\\events.py\", line 246, in handle_event\n",
      "    event_cls._handle_event(doc, event)\n",
      "  File \"c:\\Users\\joaqu\\OneDrive\\Escritorio\\Projects\\Building_Systems_ChatGPT\\llm_env\\lib\\site-packages\\bokeh\\document\\events.py\", line 281, in _handle_event\n",
      "    cb(event.msg_data)\n",
      "  File \"c:\\Users\\joaqu\\OneDrive\\Escritorio\\Projects\\Building_Systems_ChatGPT\\llm_env\\lib\\site-packages\\bokeh\\document\\callbacks.py\", line 390, in trigger_event\n",
      "    model._trigger_event(event)\n",
      "  File \"c:\\Users\\joaqu\\OneDrive\\Escritorio\\Projects\\Building_Systems_ChatGPT\\llm_env\\lib\\site-packages\\bokeh\\util\\callback_manager.py\", line 113, in _trigger_event\n",
      "    self.document.callbacks.notify_event(cast(Model, self), event, invoke)\n",
      "  File \"c:\\Users\\joaqu\\OneDrive\\Escritorio\\Projects\\Building_Systems_ChatGPT\\llm_env\\lib\\site-packages\\bokeh\\document\\callbacks.py\", line 260, in notify_event\n",
      "    invoke_with_curdoc(doc, callback_invoker)\n",
      "  File \"c:\\Users\\joaqu\\OneDrive\\Escritorio\\Projects\\Building_Systems_ChatGPT\\llm_env\\lib\\site-packages\\bokeh\\document\\callbacks.py\", line 443, in invoke_with_curdoc\n",
      "    return f()\n",
      "  File \"c:\\Users\\joaqu\\OneDrive\\Escritorio\\Projects\\Building_Systems_ChatGPT\\llm_env\\lib\\site-packages\\bokeh\\util\\callback_manager.py\", line 109, in invoke\n",
      "    cast(EventCallbackWithEvent, callback)(event)\n",
      "  File \"c:\\Users\\joaqu\\OneDrive\\Escritorio\\Projects\\Building_Systems_ChatGPT\\llm_env\\lib\\site-packages\\panel\\reactive.py\", line 491, in _server_event\n",
      "    self._comm_event(doc, event)\n",
      "  File \"c:\\Users\\joaqu\\OneDrive\\Escritorio\\Projects\\Building_Systems_ChatGPT\\llm_env\\lib\\site-packages\\panel\\reactive.py\", line 478, in _comm_event\n",
      "    state._handle_exception(e)\n",
      "  File \"c:\\Users\\joaqu\\OneDrive\\Escritorio\\Projects\\Building_Systems_ChatGPT\\llm_env\\lib\\site-packages\\panel\\io\\state.py\", line 436, in _handle_exception\n",
      "    raise exception\n",
      "  File \"c:\\Users\\joaqu\\OneDrive\\Escritorio\\Projects\\Building_Systems_ChatGPT\\llm_env\\lib\\site-packages\\panel\\reactive.py\", line 476, in _comm_event\n",
      "    self._process_bokeh_event(doc, event)\n",
      "  File \"c:\\Users\\joaqu\\OneDrive\\Escritorio\\Projects\\Building_Systems_ChatGPT\\llm_env\\lib\\site-packages\\panel\\reactive.py\", line 413, in _process_bokeh_event\n",
      "    self._process_event(event)\n",
      "  File \"c:\\Users\\joaqu\\OneDrive\\Escritorio\\Projects\\Building_Systems_ChatGPT\\llm_env\\lib\\site-packages\\panel\\widgets\\button.py\", line 243, in _process_event\n",
      "    self.clicks += 1\n",
      "  File \"c:\\Users\\joaqu\\OneDrive\\Escritorio\\Projects\\Building_Systems_ChatGPT\\llm_env\\lib\\site-packages\\param\\parameterized.py\", line 367, in _f\n",
      "    instance_param.__set__(obj, val)\n",
      "  File \"c:\\Users\\joaqu\\OneDrive\\Escritorio\\Projects\\Building_Systems_ChatGPT\\llm_env\\lib\\site-packages\\param\\parameterized.py\", line 369, in _f\n",
      "    return f(self, obj, val)\n",
      "  File \"c:\\Users\\joaqu\\OneDrive\\Escritorio\\Projects\\Building_Systems_ChatGPT\\llm_env\\lib\\site-packages\\param\\__init__.py\", line 625, in __set__\n",
      "    super(Dynamic,self).__set__(obj,val)\n",
      "  File \"c:\\Users\\joaqu\\OneDrive\\Escritorio\\Projects\\Building_Systems_ChatGPT\\llm_env\\lib\\site-packages\\param\\parameterized.py\", line 369, in _f\n",
      "    return f(self, obj, val)\n",
      "  File \"c:\\Users\\joaqu\\OneDrive\\Escritorio\\Projects\\Building_Systems_ChatGPT\\llm_env\\lib\\site-packages\\param\\parameterized.py\", line 1252, in __set__\n",
      "    obj.param._call_watcher(watcher, event)\n",
      "  File \"c:\\Users\\joaqu\\OneDrive\\Escritorio\\Projects\\Building_Systems_ChatGPT\\llm_env\\lib\\site-packages\\param\\parameterized.py\", line 2043, in _call_watcher\n",
      "    self_._execute_watcher(watcher, (event,))\n",
      "  File \"c:\\Users\\joaqu\\OneDrive\\Escritorio\\Projects\\Building_Systems_ChatGPT\\llm_env\\lib\\site-packages\\param\\parameterized.py\", line 2025, in _execute_watcher\n",
      "    watcher.fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\joaqu\\OneDrive\\Escritorio\\Projects\\Building_Systems_ChatGPT\\llm_env\\lib\\site-packages\\panel\\param.py\", line 854, in _replace_pane\n",
      "    new_object = self.eval(self.object)\n",
      "  File \"c:\\Users\\joaqu\\OneDrive\\Escritorio\\Projects\\Building_Systems_ChatGPT\\llm_env\\lib\\site-packages\\panel\\param.py\", line 813, in eval\n",
      "    return eval_function(function)\n",
      "  File \"c:\\Users\\joaqu\\OneDrive\\Escritorio\\Projects\\Building_Systems_ChatGPT\\llm_env\\lib\\site-packages\\panel\\util\\__init__.py\", line 328, in eval_function\n",
      "    return function(*args, **kwargs)\n",
      "  File \"c:\\Users\\joaqu\\OneDrive\\Escritorio\\Projects\\Building_Systems_ChatGPT\\llm_env\\lib\\site-packages\\param\\parameterized.py\", line 407, in _depends\n",
      "    return func(*args, **kw)\n",
      "  File \"c:\\Users\\joaqu\\OneDrive\\Escritorio\\Projects\\Building_Systems_ChatGPT\\llm_env\\lib\\site-packages\\panel\\depends.py\", line 249, in wrapped\n",
      "    return eval_fn()(*combined_args, **combined_kwargs)\n",
      "  File \"c:\\Users\\joaqu\\OneDrive\\Escritorio\\AI Projects\\Query_your_files\\objects.py\", line 63, in call_load_db\n",
      "    if count == 0 or file_input.value is None:  # init or no file specified :\n",
      "AttributeError: 'NoneType' object has no attribute 'value'\n"
     ]
    }
   ],
   "source": [
    "c=objects.cbfs()\n",
    "c.build_ui().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def current_model():\n",
    "    current_date = datetime.datetime.now().date()\n",
    "    target_date = datetime.date(2024, 6, 12)\n",
    "    if current_date < target_date:\n",
    "        llm_name = \"gpt-3.5-turbo-0301\"\n",
    "    else:\n",
    "        llm_name = \"gpt-3.5-turbo-0613\"\n",
    "    print(f\"Fecha:{current_date}\\nUsando modelo {llm_name}\")\n",
    "    return llm_name\n",
    "\n",
    "\n",
    "\n",
    "def load_db(file, chain_type, k):\n",
    "    \n",
    "    persist_directory = f\"./chroma\"\n",
    "    # load documents\n",
    "    loader = PyPDFLoader(file)\n",
    "    documents = loader.load()\n",
    "    # split documents\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    # define embedding\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    # create vector database from data\n",
    "    db = Chroma.from_documents(docs, embeddings,persist_directory=persist_directory)\n",
    "    # define retriever\n",
    "    retriever = db.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": k})\n",
    "    # create a chatbot chain. Memory is managed externally.\n",
    "    llm_name=current_model()\n",
    "    qa = ConversationalRetrievalChain.from_llm(\n",
    "        llm=ChatOpenAI(model_name=llm_name, temperature=0), \n",
    "        chain_type=chain_type, \n",
    "        retriever=retriever, \n",
    "        return_source_documents=True,\n",
    "        return_generated_question=True,\n",
    "    )\n",
    "    return qa \n",
    "\n",
    "class cbfs(param.Parameterized):\n",
    "    chat_history = param.List([])\n",
    "    answer = param.String(\"\")\n",
    "    db_query  = param.String(\"\")\n",
    "    db_response = param.List([])\n",
    "    \n",
    "    def __init__(self,  **params):\n",
    "        super(cbfs, self).__init__( **params)\n",
    "        self.panels = []\n",
    "        self.loaded_file = \"docs/tgi.pdf\" \n",
    "        self.qa = load_db(self.loaded_file,\"stuff\", 4)\n",
    "    \n",
    "    def call_load_db(self, count):\n",
    "        if count == 0 or file_input.value is None:  # init or no file specified :\n",
    "            return pn.pane.Markdown(f\"Loaded File: {self.loaded_file}\")\n",
    "        else:\n",
    "            file_input.save(\"temp.pdf\")  # local copy\n",
    "            self.loaded_file = file_input.filename\n",
    "            button_load.button_style=\"outline\"\n",
    "            self.qa = load_db(\"temp.pdf\", \"stuff\", 4)\n",
    "            button_load.button_style=\"solid\"\n",
    "        self.clr_history()\n",
    "        return pn.pane.Markdown(f\"Loaded File: {self.loaded_file}\")\n",
    "    @param.depends('clr_history',)\n",
    "    def convchain(self, query):\n",
    "        if not query:\n",
    "            return pn.WidgetBox(pn.Row('User:', pn.pane.Markdown(\"\", width=700)), scroll=True)\n",
    "        result = self.qa({\"question\": query, \"chat_history\": self.chat_history})\n",
    "        self.chat_history.extend([(query, result[\"answer\"])])\n",
    "        self.db_query = result[\"generated_question\"]\n",
    "        self.db_response = result[\"source_documents\"]\n",
    "        self.answer = result['answer'] \n",
    "        self.panels.extend([\n",
    "            pn.Row('Usuario:', pn.pane.Markdown(query, width=700)),\n",
    "            pn.Row('ChatBot:', pn.pane.Markdown(self.answer, width=700, style={'background-color': '#ffcc00'}))\n",
    "        ])\n",
    "        inp.value = ''  #clears loading indicator when cleared\n",
    "        return pn.WidgetBox(*self.panels,scroll=True)\n",
    "\n",
    "    @param.depends('db_query ', )\n",
    "    def get_lquest(self):\n",
    "        if not self.db_query :\n",
    "            return pn.Column(\n",
    "                pn.Row(pn.pane.Markdown(f\"Last question to DB:\", styles={'background-color': '#F6F6F6'})),\n",
    "                pn.Row(pn.pane.Str(\"no DB accesses so far\"))\n",
    "            )\n",
    "        return pn.Column(\n",
    "            pn.Row(pn.pane.Markdown(f\"DB query:\", styles={'background-color': '#F6F6F6'})),\n",
    "            pn.pane.Str(self.db_query )\n",
    "        )\n",
    "\n",
    "    @param.depends('db_response', )\n",
    "    def get_sources(self):\n",
    "        if not self.db_response:\n",
    "            return \n",
    "        rlist=[pn.Row(pn.pane.Markdown(f\"Result of DB lookup:\", styles={'background-color': '#F6F6F6'}))]\n",
    "        for doc in self.db_response:\n",
    "            rlist.append(pn.Row(pn.pane.Str(doc)))\n",
    "        return pn.WidgetBox(*rlist, width=600, scroll=True)\n",
    "\n",
    "    @param.depends('convchain', 'clr_history') \n",
    "    def get_chats(self):\n",
    "        if not self.chat_history:\n",
    "            return pn.WidgetBox(pn.Row(pn.pane.Str(\"No History Yet\")), width=600, scroll=True)\n",
    "        rlist=[pn.Row(pn.pane.Markdown(f\"Current Chat History variable\", styles={'background-color': '#F6F6F6'}))]\n",
    "        for exchange in self.chat_history:\n",
    "            rlist.append(pn.Row(pn.pane.Str(exchange)))\n",
    "        return pn.WidgetBox(*rlist, width=600, scroll=True)\n",
    "\n",
    "    \n",
    "    def clr_history(self,count=0):\n",
    "        self.chat_history = []\n",
    "        self.panels=[]\n",
    "        return \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fecha:2024-01-24\n",
      "Usando modelo gpt-3.5-turbo-0301\n",
      "Launching server at http://localhost:50901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<panel.io.server.Server at 0x1b4d259c9a0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb = cbfs()\n",
    "\n",
    "file_input = pn.widgets.FileInput(accept='.pdf')\n",
    "button_load = pn.widgets.Button(name=\"Load DB\", button_type='primary')\n",
    "button_clearhistory = pn.widgets.Button(name=\"Clear History\", button_type='warning',icon='caret-right')\n",
    "button_clearhistory.on_click(cb.clr_history)\n",
    "inp = pn.widgets.TextInput( placeholder='Escriba aqui para comenzar a chatear...',width=600)\n",
    "\n",
    "bound_button_load = pn.bind(cb.call_load_db, button_load.param.clicks)\n",
    "conversation = pn.bind(cb.convchain, inp) \n",
    "jpg_pane = pn.pane.Image( './img/convchain.jpg')\n",
    "tab1 = pn.Column(\n",
    "    pn.Row(inp),\n",
    "    pn.layout.Divider(),\n",
    "    pn.panel(conversation,  loading_indicator=True),\n",
    "    pn.layout.Divider(),\n",
    ")\n",
    "tab2= pn.Column(\n",
    "    pn.panel(cb.get_lquest),\n",
    "    pn.layout.Divider(),\n",
    "    pn.panel(cb.get_sources ),\n",
    ")\n",
    "tab3= pn.Column(\n",
    "    pn.panel(cb.get_chats),\n",
    "    pn.layout.Divider(),\n",
    ")\n",
    "tab4=pn.Column(\n",
    "    pn.Row( file_input, button_load, bound_button_load),\n",
    "    pn.Row( button_clearhistory, pn.pane.Markdown(\"Clears chat history. Can use to start a new topic\" )),\n",
    "    pn.layout.Divider(),\n",
    "    pn.Row(jpg_pane.clone(width=400))\n",
    ")\n",
    "dashboard = pn.Column(\n",
    "    pn.Row(pn.pane.Markdown('# Chatea con tus archivosüóÉÔ∏è')),\n",
    "    pn.Tabs(('Conversation', tab1), ('Database', tab2), ('Chat History', tab3),('Configure', tab4))\n",
    ")\n",
    "dashboard.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "llm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
